{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_STEMEER = True\n",
    "SEED = 42\n",
    "QUICK = True\n",
    "TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# seeding function for reproducibility\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and removing unnecessary columns\n",
    "df = pd.read_csv(\"../input/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "                 encoding=\"latin1\",\n",
    "                 header=None)\n",
    "df = df.rename(columns={0:\"sentiment\",\n",
    "                        1:\"id\",\n",
    "                        2:\"time\",\n",
    "                        3:\"query\",\n",
    "                        4:\"username\",\n",
    "                        5:\"text\"})\n",
    "df = df[[\"sentiment\",\"text\"]]\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({0: 0, 4: 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()\n",
    "# Looks like dataset is well balanced :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "use_stemmer = USE_STEMEER\n",
    "if use_stemmer:\n",
    "      porter_stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    return word\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|;\\s?D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    processed_tweet = []\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "        processed_tweet.append(word)\n",
    "    return ' '.join(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "user_ment url  aww that a bummer you shoulda got david carr of third day to do it emo_po\n"
     ]
    }
   ],
   "source": [
    "# Example output\n",
    "print(df.text[0])\n",
    "print(preprocess_tweet(df.text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 28s, sys: 1.64 s, total: 16min 30s\n",
      "Wall time: 16min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Processed_text'] = df.text.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>user_ment url  aww that a bummer you shoulda g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant updat hi facebook by tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>user_ment i dive mani time for the ball manag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole bodi feel itchi and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>user_ment no it not behav at all im mad whi am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                      Processed_text  \n",
       "0  user_ment url  aww that a bummer you shoulda g...  \n",
       "1  is upset that he cant updat hi facebook by tex...  \n",
       "2  user_ment i dive mani time for the ball manag ...  \n",
       "3       my whole bodi feel itchi and like it on fire  \n",
       "4  user_ment no it not behav at all im mad whi am...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_model(Xtrain, Xtest, ytrain, ytest, quick=QUICK):\n",
    "    \"\"\"\n",
    "    quick Boolean: \n",
    "    \"\"\"\n",
    "    if quick:\n",
    "        clf = LogisticRegression()\n",
    "    else:\n",
    "        parameters = {'C':[0.01, 0.1, 1, 5, 10, 100]}\n",
    "        clf = LogisticRegression()\n",
    "        grid_search = GridSearchCV(clf,\n",
    "                                   parameters,\n",
    "                                   cv=StratifiedKFold(n_splits=3,random_state=42)\\\n",
    "                                   .split(X_train, y_train),\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=4)\n",
    "        clf = grid_search.fit(X_train, y_train)\n",
    "        clf = LogisticRegression(C=clf.best_params_['C'])\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_preds = clf.predict(X_test)\n",
    "    probability = clf.predict_proba(X_test)[:,1]\n",
    "    print(f\"Accuracy is {accuracy_score(y_test, y_preds)} AUC is {roc_auc_score(y_test, probability)}\")\n",
    "    print(classification_report(y_test, y_preds))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_features(coefs, my_map,  K=10):\n",
    "    a = [my_map[i] for i in coefs.argsort()[-K:][::-1]]\n",
    "    b = [coefs[i] for i in coefs.argsort()[-K:][::-1]]\n",
    "    c = [my_map[i] for i in coefs.argsort()[:K]]\n",
    "    d = [coefs[i] for i in coefs.argsort()[:K]]\n",
    "    print(f\"{'Positive_features': <20} {'coef': <5} \\t\\t {'negative_features': <20} {'coef': <5}\")\n",
    "    print(\"-\"*70)\n",
    "    for i,j,k,l in zip(a,b,c,d):\n",
    "        print(f\"{i: <20} {j:.4f} \\t\\t {k: <20} {l:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X__train, X__test, y_train, y_test=train_test_split(df['Processed_text'],\n",
    "                                              df['sentiment'],\n",
    "                                              test_size=TEST_SIZE,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 234111\n",
      "CPU times: user 1min 11s, sys: 1.19 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "print(f\"number of features = {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.77755 AUC is 0.8524289583982977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77     79812\n",
      "           1       0.77      0.80      0.78     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "fuzzbal              2.5672 \t\t nanda                -3.7418\n",
      "excitedd             2.5044 \t\t inaperfectworld      -3.7023\n",
      "myfax                2.4921 \t\t sadd                 -3.6137\n",
      "emailunlimit         2.4684 \t\t sadden               -3.4210\n",
      "smilin               2.4482 \t\t dontyouh             -3.3968\n",
      "mahasha              2.3457 \t\t pakcricket           -3.2005\n",
      "lml                  2.2920 \t\t cries                -3.1300\n",
      "happyy               2.2752 \t\t sad                  -3.1136\n",
      "goodsex              2.2046 \t\t sadli                -3.0213\n",
      "flyy                 2.1921 \t\t sadfac               -2.9513\n",
      "CPU times: user 3min 8s, sys: 770 ms, total: 3min 9s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limited Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 78 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", max_features=10000)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7765125 AUC is 0.8515266046650493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77     79812\n",
      "           1       0.76      0.80      0.78     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "fuzzbal              2.5819 \t\t inaperfectworld      -3.7611\n",
      "excitedd             2.4598 \t\t sadd                 -3.5161\n",
      "emailunlimit         2.4123 \t\t dontyouh             -3.4283\n",
      "happyy               2.2168 \t\t sadden               -3.3644\n",
      "goodsex              2.1868 \t\t pakcricket           -3.2178\n",
      "reliev               2.0177 \t\t cries                -3.1333\n",
      "musicmonday          1.9592 \t\t sad                  -3.0907\n",
      "smile                1.9448 \t\t sadfac               -2.9900\n",
      "congratul            1.9369 \t\t sadli                -2.9793\n",
      "thanki               1.9199 \t\t condol               -2.9290\n",
      "CPU times: user 1min 4s, sys: 290 ms, total: 1min 5s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 13 ms, total: 30.9 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = HashingVectorizer(stop_words=\"english\")#, n_features=2**20)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.779475 AUC is 0.8602496972133279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77     79812\n",
      "           1       0.77      0.80      0.78     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "CPU times: user 1min 34s, sys: 146 ms, total: 1min 35s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 3413468\n",
      "CPU times: user 2min 42s, sys: 3.5 s, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "print(f\"number of features = {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.79118125 AUC is 0.8674078095565033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79     79812\n",
      "           1       0.78      0.81      0.80     80188\n",
      "\n",
      "    accuracy                           0.79    160000\n",
      "   macro avg       0.79      0.79      0.79    160000\n",
      "weighted avg       0.79      0.79      0.79    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "wish luck            3.8954 \t\t sad                  -3.6296\n",
      "doesnt hurt          3.5806 \t\t sadd                 -3.6009\n",
      "wont hurt            3.4848 \t\t inaperfectworld      -3.5761\n",
      "sad sad              3.2333 \t\t sadli                -3.4834\n",
      "wont disappoint      3.2270 \t\t pass away            -3.2902\n",
      "aint bad             3.2125 \t\t sadden               -3.2625\n",
      "isnt bad             3.1350 \t\t cries                -3.2094\n",
      "noth wrong           3.0072 \t\t dontyouh             -3.1184\n",
      "sorri delay          2.9741 \t\t break heart          -3.0109\n",
      "dont miss            2.9488 \t\t devast               -2.9924\n",
      "CPU times: user 19min 46s, sys: 6.18 s, total: 19min 53s\n",
      "Wall time: 18min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 10000\n",
      "CPU times: user 2min 31s, sys: 1.71 s, total: 2min 33s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=10000)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "print(f\"number of features = {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7813875 AUC is 0.8583408145621485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77     79812\n",
      "           1       0.77      0.81      0.79     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "wish luck            3.3646 \t\t inaperfectworld      -3.7768\n",
      "sad sad              2.9326 \t\t sadd                 -3.4387\n",
      "isnt bad             2.8755 \t\t sadden               -3.2612\n",
      "dont miss            2.6319 \t\t cries                -3.1073\n",
      "wasnt bad            2.6243 \t\t sad                  -3.0763\n",
      "noth wrong           2.5804 \t\t sadli                -3.0618\n",
      "dont sad             2.4157 \t\t pass away            -2.9815\n",
      "dont worri           2.1909 \t\t lost pleas           -2.9784\n",
      "whi thank            2.0648 \t\t condol               -2.8278\n",
      "dont forget          1.9758 \t\t boohoo               -2.8226\n",
      "CPU times: user 1min 30s, sys: 60 ms, total: 1min 30s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 100000\n",
      "CPU times: user 2min 33s, sys: 1.42 s, total: 2min 34s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 2) , max_features=100000)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "print(f\"number of features = {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.78826875 AUC is 0.864436685570346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78     79812\n",
      "           1       0.78      0.81      0.79     80188\n",
      "\n",
      "    accuracy                           0.79    160000\n",
      "   macro avg       0.79      0.79      0.79    160000\n",
      "weighted avg       0.79      0.79      0.79    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "doesnt hurt          3.6514 \t\t inaperfectworld      -3.7542\n",
      "wish luck            3.6408 \t\t sadd                 -3.3917\n",
      "wont disappoint      3.3058 \t\t dontyouh             -3.3754\n",
      "wont hurt            3.2642 \t\t sad                  -3.3653\n",
      "sad sad              3.1557 \t\t pic reason           -3.3361\n",
      "aint bad             3.0752 \t\t cries                -3.2535\n",
      "wont miss            2.9695 \t\t pakcricket           -3.2516\n",
      "didnt hurt           2.9296 \t\t sadden               -3.2473\n",
      "didnt miss           2.9292 \t\t sadli                -3.2040\n",
      "sorri delay          2.8868 \t\t pass away            -3.1677\n",
      "CPU times: user 5min 22s, sys: 235 ms, total: 5min 22s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.8 s, sys: 452 ms, total: 46.3 s\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = HashingVectorizer(stop_words=\"english\",  ngram_range=(1, 2))#, n_features=2**20)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7914875 AUC is 0.8736302615762446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79     79812\n",
      "           1       0.78      0.81      0.80     80188\n",
      "\n",
      "    accuracy                           0.79    160000\n",
      "   macro avg       0.79      0.79      0.79    160000\n",
      "weighted avg       0.79      0.79      0.79    160000\n",
      "\n",
      "CPU times: user 2min 18s, sys: 113 ms, total: 2min 18s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 1.81 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = HashingVectorizer(stop_words=\"english\",  ngram_range=(1, 4))#, n_features=2**20)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.78754375 AUC is 0.8701233515843341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78     79812\n",
      "           1       0.78      0.81      0.79     80188\n",
      "\n",
      "    accuracy                           0.79    160000\n",
      "   macro avg       0.79      0.79      0.79    160000\n",
      "weighted avg       0.79      0.79      0.79    160000\n",
      "\n",
      "CPU times: user 3min 18s, sys: 304 ms, total: 3min 19s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 58 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             ngram_range=(1, 1),\n",
    "                             max_df=0.5, \n",
    "                             min_df=5, \n",
    "                             max_features=None,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.77775625 AUC is 0.8581793905456843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77     79812\n",
      "           1       0.77      0.80      0.78     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "thank                5.0583 \t\t sad                  -10.6170\n",
      "smile                4.5882 \t\t miss                 -6.9778\n",
      "welcom               4.3479 \t\t sadli                -6.9738\n",
      "proud                4.0340 \t\t poor                 -6.5698\n",
      "congratul            3.9762 \t\t unfortun             -6.0787\n",
      "glad                 3.9327 \t\t sick                 -5.7863\n",
      "reliev               3.7688 \t\t depress              -5.6400\n",
      "pleasur              3.5938 \t\t sadden               -5.5915\n",
      "awesom               3.5037 \t\t disappoint           -5.5808\n",
      "hehe                 3.4651 \t\t upset                -5.5495\n",
      "CPU times: user 45.7 s, sys: 20 ms, total: 45.7 s\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 24.1 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             ngram_range=(1, 1),\n",
    "                             max_df=0.5, \n",
    "                             min_df=5, \n",
    "                             max_features=10000,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7754 AUC is 0.8559772699469734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77     79812\n",
      "           1       0.77      0.80      0.78     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "thank                4.8635 \t\t sad                  -10.1334\n",
      "smile                4.4192 \t\t sadli                -6.6699\n",
      "welcom               4.2110 \t\t miss                 -6.5492\n",
      "proud                3.8456 \t\t poor                 -6.1955\n",
      "congratul            3.8310 \t\t unfortun             -5.8539\n",
      "glad                 3.7437 \t\t sick                 -5.5586\n",
      "reliev               3.7171 \t\t sadden               -5.4078\n",
      "pleasur              3.5089 \t\t depress              -5.3979\n",
      "awesom               3.3533 \t\t disappoint           -5.3431\n",
      "congrat              3.3210 \t\t upset                -5.3423\n",
      "CPU times: user 30.8 s, sys: 24 ms, total: 30.9 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 37s, sys: 1.31 s, total: 2min 39s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_df=0.5, \n",
    "                             min_df=5, \n",
    "                             max_features=None,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.79410625 AUC is 0.8761462433613789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79     79812\n",
      "           1       0.78      0.81      0.80     80188\n",
      "\n",
      "    accuracy                           0.79    160000\n",
      "   macro avg       0.79      0.79      0.79    160000\n",
      "weighted avg       0.79      0.79      0.79    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "wish luck            8.7819 \t\t sad                  -16.1624\n",
      "thank                7.9070 \t\t miss                 -11.2604\n",
      "dont worri           7.0560 \t\t sadli                -9.9359\n",
      "smile                6.5034 \t\t poor                 -9.6310\n",
      "isnt bad             6.2690 \t\t unfortun             -8.9120\n",
      "welcom               6.0191 \t\t wish                 -8.8630\n",
      "wasnt bad            5.9651 \t\t sick                 -8.6440\n",
      "dont forget          5.8576 \t\t hurt                 -8.1435\n",
      "doesnt hurt          5.8102 \t\t hate                 -7.9676\n",
      "proud                5.6338 \t\t disappoint           -7.6286\n",
      "CPU times: user 1min 2s, sys: 26.9 ms, total: 1min 2s\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 890 ms, total: 2min 32s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_df=0.5, \n",
    "                             min_df=5, \n",
    "                             max_features=10000,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "my_map ={v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.78054375 AUC is 0.8632507273021415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77     79812\n",
      "           1       0.77      0.80      0.79     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "Positive_features    coef  \t\t negative_features    coef \n",
      "----------------------------------------------------------------------\n",
      "wish luck            6.6818 \t\t sad                  -11.3654\n",
      "thank                5.5114 \t\t sadli                -7.6178\n",
      "dont worri           5.3711 \t\t miss                 -7.4964\n",
      "isnt bad             5.0034 \t\t poor                 -6.8534\n",
      "wasnt bad            4.8235 \t\t unfortun             -6.7797\n",
      "smile                4.7964 \t\t sick                 -5.9647\n",
      "dont forget          4.5864 \t\t wish                 -5.9476\n",
      "welcom               4.3645 \t\t pass away            -5.8808\n",
      "noth wrong           4.3382 \t\t depress              -5.7182\n",
      "proud                4.1551 \t\t bummer               -5.5518\n",
      "CPU times: user 40.6 s, sys: 31 ms, total: 40.6 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)\n",
    "print_top_features(clf.coef_.copy()[0], my_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 20000\n",
      "CPU times: user 5min 4s, sys: 2.51 s, total: 5min 6s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scipy.sparse import hstack\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_df=0.5, \n",
    "                             min_df=5, \n",
    "                             max_features=10000,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "vectorizer.fit(X__train)\n",
    "X_train = vectorizer.transform(X__train)\n",
    "X_test = vectorizer.transform(X__test)\n",
    "\n",
    "vectorizer2 = CountVectorizer(stop_words=\"english\",\n",
    "                              ngram_range=(1, 2) ,\n",
    "                              max_features=10000)\n",
    "vectorizer2.fit(X__train)\n",
    "X_train2 = vectorizer.transform(X__train)\n",
    "X_test2 = vectorizer.transform(X__test)\n",
    "X_train = hstack((X_train, X_train2))\n",
    "X_test = hstack((X_test, X_test2))\n",
    "print(f\"number of features = {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.78045625 AUC is 0.86319955092577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77     79812\n",
      "           1       0.77      0.81      0.79     80188\n",
      "\n",
      "    accuracy                           0.78    160000\n",
      "   macro avg       0.78      0.78      0.78    160000\n",
      "weighted avg       0.78      0.78      0.78    160000\n",
      "\n",
      "CPU times: user 1min 22s, sys: 274 ms, total: 1min 22s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = train_model(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
