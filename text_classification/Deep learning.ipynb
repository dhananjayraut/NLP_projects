{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm as tq\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_STEMEER = False\n",
    "SEED = 42\n",
    "QUICK = True\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# seeding function for reproducibility\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and removing unnecessary columns\n",
    "df = pd.read_csv(\"../input/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "                 encoding=\"latin1\",\n",
    "                 header=None)\n",
    "df = df.rename(columns={0:\"sentiment\",\n",
    "                        1:\"id\",\n",
    "                        2:\"time\",\n",
    "                        3:\"query\",\n",
    "                        4:\"username\",\n",
    "                        5:\"text\"})\n",
    "df = df[[\"sentiment\",\"text\"]]\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({0: 0, 4: 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()\n",
    "# Looks like dataset is well balanced :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "use_stemmer = USE_STEMEER\n",
    "if use_stemmer:\n",
    "      porter_stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    return word\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|;\\s?D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    processed_tweet = []\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip('\"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "        processed_tweet.append(word)\n",
    "    return ' '.join(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "user_mention url  aww thats a bummer you shoulda got david carr of third day to do it emo_pos\n"
     ]
    }
   ],
   "source": [
    "# Example output\n",
    "print(df.text[0])\n",
    "print(preprocess_tweet(df.text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 493 ms, total: 5min 5s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Processed_text'] = df.text.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>user_mention url  aww thats a bummer you shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>user_mention i dived many times for the ball m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>user_mention no its not behaving at all im mad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                      Processed_text  \n",
       "0  user_mention url  aww thats a bummer you shoul...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2  user_mention i dived many times for the ball m...  \n",
       "3     my whole body feels itchy and like its on fire  \n",
       "4  user_mention no its not behaving at all im mad...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Processed_text\", \"sentiment\"]]\n",
    "df.to_csv(\"train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "tweet = torchtext.data.Field(lower=True) # , tokenize=\"spacy\")\n",
    "targets = torchtext.data.RawField(is_target=True)\n",
    "fields = [(\"Processed_text\",tweet ), (\"sentiment\",targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 s, sys: 1.34 s, total: 43.7 s\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = TabularDataset(path=\"./train.csv\", format=\"CSV\", fields=fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                           \n",
      "100%|█████████▉| 399470/400000 [00:26<00:00, 15211.95it/s]"
     ]
    }
   ],
   "source": [
    "tweet.build_vocab(dataset, max_size=100_000, min_freq=5, vectors=\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57280\n"
     ]
    }
   ],
   "source": [
    "vocab = tweet.vocab\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dataset.split(1-TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "biter = torchtext.data.BucketIterator(dataset=train_dataset, \n",
    "                                      batch_size=4,\n",
    "                                      sort_key=lambda x: len(x.comment_text),\n",
    "                                      train=True, \n",
    "                                      sort=False,\n",
    "                                      shuffle=True)\n",
    "for i in biter:\n",
    "    print(i.Processed_text.shape)\n",
    "    print(len(i.sentiment))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_biter = torchtext.data.BucketIterator(dataset=train_dataset, \n",
    "                                      batch_size=100,\n",
    "                                      sort_key=lambda x: len(x.comment_text),\n",
    "                                      train=True, \n",
    "                                      sort=False,\n",
    "                                      shuffle=True)\n",
    "valid_biter = torchtext.data.BucketIterator(dataset=valid_dataset, \n",
    "                                      batch_size=100,\n",
    "                                      sort_key=lambda x: len(x.comment_text),\n",
    "                                      train=True, \n",
    "                                      sort=False,\n",
    "                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399470/400000 [00:40<00:00, 15211.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57279\n"
     ]
    }
   ],
   "source": [
    "MAX = -1\n",
    "for text, cls in valid_biter:\n",
    "    MAX = max(MAX, torch.max(text).item())\n",
    "for text, cls in train_biter:\n",
    "    MAX = max(MAX, torch.max(text).item())\n",
    "print(MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextSentiment(nn.Module):\n",
    "    \"\"\"\n",
    "    from torchtext examples\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        r\"\"\"\n",
    "        Arguments:\n",
    "            text: 1-D tensor representing a bag of text tensors\n",
    "        \"\"\"\n",
    "        x = self.embedding(text)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TextSentiment(vocab_size, embed_dim=100, num_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.require_grad = False\n",
    "#model.embedding.require_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "for text, cls in train_biter:\n",
    "    cls = torch.tensor([int(i) for i in cls])\n",
    "    text = text.T\n",
    "    output = model(text)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training   loss : 0.6167557886173017\n",
      "validation loss : 0.6130311371944844\n",
      "validation acc  : 0.6494156250000094\n",
      "epoch 1\n",
      "training   loss : 0.5565248841885477\n",
      "validation loss : 0.5341699340287596\n",
      "validation acc  : 0.7375093750000036\n",
      "epoch 2\n",
      "training   loss : 0.5360430646222085\n",
      "validation loss : 0.5567478049639613\n",
      "validation acc  : 0.7033531250000131\n",
      "epoch 3\n",
      "training   loss : 0.5254401282477192\n",
      "validation loss : 0.5123430011235177\n",
      "validation acc  : 0.7516062499999984\n",
      "epoch 4\n",
      "training   loss : 0.5165074256272055\n",
      "validation loss : 0.5066159102600067\n",
      "validation acc  : 0.7601374999999981\n",
      "epoch 5\n",
      "training   loss : 0.5000989233423024\n",
      "validation loss : 0.49557027911767365\n",
      "validation acc  : 0.7715031249999954\n",
      "epoch 6\n",
      "training   loss : 0.4972173641738482\n",
      "validation loss : 0.49462904264219104\n",
      "validation acc  : 0.7684999999999959\n",
      "epoch 7\n",
      "training   loss : 0.4952928430680186\n",
      "validation loss : 0.4932508804276586\n",
      "validation acc  : 0.7686593749999973\n",
      "epoch 8\n",
      "training   loss : 0.4932814750424586\n",
      "validation loss : 0.48879914023913446\n",
      "validation acc  : 0.7762718749999962\n",
      "epoch 9\n",
      "training   loss : 0.4917518632300198\n",
      "validation loss : 0.48811628576368093\n",
      "validation acc  : 0.7733718749999947\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc  = 0.0\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    bar = tq(train_biter, postfix={\"train_loss\":0.0, \"Accuracy\":0.0}, leave=False, disable=True)\n",
    "    for text, cls in bar:\n",
    "        optimizer.zero_grad()\n",
    "        cls = torch.tensor([int(i) for i in cls])\n",
    "        text = text.T\n",
    "        output = model(text)\n",
    "        loss = criterion(output, cls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        acc = torch.sum(cls == torch.argmax(output, axis=1)).item() / cls.shape[0]\n",
    "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item() , \"Accuracy\":acc})\n",
    "    \n",
    "    model.eval()\n",
    "    LOSS = 0.0\n",
    "    i  = 0\n",
    "    with torch.no_grad():\n",
    "        bar = tq(valid_biter, postfix={\"valid_loss\":0.0, \"Accuracy\":0.0}, leave=False, disable=True)\n",
    "        for text, cls in bar:\n",
    "            cls = torch.tensor([int(i) for i in cls])\n",
    "            text = text.T\n",
    "            output = model(text)\n",
    "            loss = criterion(output, cls)\n",
    "            acc = torch.sum(cls == torch.argmax(output, axis=1)).item() / cls.shape[0]\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += acc\n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"Accuracy\":acc})\n",
    "    \n",
    "    print(f\"epoch {epoch}\")\n",
    "    print(f\"training   loss : {train_loss/len(train_biter)}\")\n",
    "    print(f\"validation loss : {valid_loss/len(valid_biter)}\")\n",
    "    print(f\"validation acc  : {valid_acc/len(valid_biter)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextSentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    from torchtext examples\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        self.LSTM = nn.LSTM(embed_dim, 40, 1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(40*2, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        r\"\"\"\n",
    "        Arguments:\n",
    "            text: 1-D tensor representing a bag of text tensors\n",
    "        \"\"\"\n",
    "        x = self.embedding(text)\n",
    "        x = self.LSTM(x)\n",
    "        h = torch.transpose(x[1][0], 0, 1)\n",
    "        h = torch.reshape(h, (h.shape[0], -1))\n",
    "        return self.fc(h)\n",
    "\n",
    "model = TextSentimentLSTM(vocab_size, embed_dim=100, num_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training   loss : 0.5463770840130746\n",
      "validation loss : 0.4868140486255288\n",
      "validation acc  : 0.7636468749999956\n",
      "epoch 1\n",
      "training   loss : 0.4715270173503086\n",
      "validation loss : 0.4559296695981175\n",
      "validation acc  : 0.7832468749999961\n",
      "epoch 2\n",
      "training   loss : 0.44864414104493333\n",
      "validation loss : 0.4402766204159707\n",
      "validation acc  : 0.7933031249999928\n",
      "epoch 3\n",
      "training   loss : 0.43469986379845066\n",
      "validation loss : 0.43563658468425276\n",
      "validation acc  : 0.7951468749999928\n",
      "epoch 4\n",
      "training   loss : 0.4249087890703231\n",
      "validation loss : 0.4235063418187201\n",
      "validation acc  : 0.8024656249999904\n",
      "epoch 5\n",
      "training   loss : 0.4165096571436152\n",
      "validation loss : 0.41776211448013784\n",
      "validation acc  : 0.8061999999999919\n",
      "epoch 6\n",
      "training   loss : 0.4129209479445126\n",
      "validation loss : 0.4174101486802101\n",
      "validation acc  : 0.8067968749999924\n",
      "epoch 7\n",
      "training   loss : 0.4097412711556535\n",
      "validation loss : 0.41239662929903714\n",
      "validation acc  : 0.8096499999999888\n",
      "epoch 8\n",
      "training   loss : 0.40679522514576094\n",
      "validation loss : 0.4104234265163541\n",
      "validation acc  : 0.8103843749999915\n",
      "epoch 9\n",
      "training   loss : 0.4040989736490883\n",
      "validation loss : 0.4097125041019172\n",
      "validation acc  : 0.8114093749999887\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc  = 0.0\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    bar = tq(train_biter, postfix={\"train_loss\":0.0, \"Accuracy\":0.0}, leave=False, disable=True)\n",
    "    for text, cls in bar:\n",
    "        optimizer.zero_grad()\n",
    "        cls = torch.tensor([int(i) for i in cls])\n",
    "        text = text.T\n",
    "        output = model(text)\n",
    "        loss = criterion(output, cls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        acc = torch.sum(cls == torch.argmax(output, axis=1)).item() / cls.shape[0]\n",
    "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item() , \"Accuracy\":acc})\n",
    "    \n",
    "    model.eval()\n",
    "    LOSS = 0.0\n",
    "    i  = 0\n",
    "    with torch.no_grad():\n",
    "        bar = tq(valid_biter, postfix={\"valid_loss\":0.0, \"Accuracy\":0.0}, leave=False, disable=True)\n",
    "        for text, cls in bar:\n",
    "            cls = torch.tensor([int(i) for i in cls])\n",
    "            text = text.T\n",
    "            output = model(text)\n",
    "            loss = criterion(output, cls)\n",
    "            acc = torch.sum(cls == torch.argmax(output, axis=1)).item() / cls.shape[0]\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += acc\n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"Accuracy\":acc})\n",
    "    \n",
    "    print(f\"epoch {epoch}\")\n",
    "    print(f\"training   loss : {train_loss/len(train_biter)}\")\n",
    "    print(f\"validation loss : {valid_loss/len(valid_biter)}\")\n",
    "    print(f\"validation acc  : {valid_acc/len(valid_biter)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
